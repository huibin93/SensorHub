传感器文件数据模型模块 重新设计
场景 1：正常上传

上传 sensor.rawdata (Hash: A)

物理表：插入 Hash: A

用户表：插入 filename: sensor.rawdata, file_hash: A

结果：存盘 1 次，数据库 2 条记录。
场景 2：文件名重复，内容也重复 (完全秒传)

再次上传 sensor.rawdata (Hash: A)

物理表：发现 Hash: A 已存在 (size 也同样大小) -> 秒传 (物理文件不增加)。
不做任何数据库操作,  返回成功消息, 提示用户文件已存在。

场景 3：文件名不同，内容重复 (拷贝)

上传 backup.rawdata (Hash: A)

物理表：发现 Hash: A 已存在 -> 秒传。

用户表：发现 backup.rawdata 不存在 -> 不重命名。

插入记录：filename: backup.rawdata, file_hash: A。

结果：实现了“复制”功能，完全不占额外硬盘空间。
场景 4：文件名相同，内容不同 (冲突)

上传 sensor.rawdata (Hash: B - 新数据)

物理表：Hash: B 不存在 -> 存盘。

用户表：sensor.rawdata 已存在 -> 重命名为 sensor_1.rawdata

插入记录：filename: sensor_1.rawdata, file_hash: B。

需求解决方案保证后端数据唯一使用 physical_files 表，主键为 Hash。文件名避免重复使用 user_files 表，写入前在 Python 中做 while exists 检查并添加后缀。ID 选择user_files 使用 UUID，不要用文件名做 ID。秒传实现上传前检查 Hash 是否在 physical_files 表中。

==============================================================

当 文件hash (md5) 一致 但大小不同  1/2^128 的概率
也许 人类文明终结的时间尺度也不会出现
1. 后端：使用 HTTP 418 (I'm a teapot)
HTTP 协议里有一个专门用来搞怪的状态码：418 I'm a teapot（我是一个茶壶）。用在这里再合适不过了——因为发生了这种事，服务器除了“变成一个茶壶卖萌”，也解释不清为什么。

后端代码 (backend/app/api/v1/endpoints/files.py)：

Python
from fastapi.responses import JSONResponse

# ... 在检测到 Hash 相同但 Size 不同时 ...

if existing_file.size != incoming_size:
    # 记录一条最高级别的日志，万一管理员真的看到了呢
    logger.critical(
        f"🌌 COSMIC EVENT DETECTED: MD5 Collision! "
        f"Hash: {incoming_hash} | "
        f"Existing Size: {existing_file.size} vs New Size: {incoming_size}"
    )
    
    return JSONResponse(
        status_code=418,  # <--- 彩蛋核心
        content={
            "error_code": "COSMIC_BIT_FLIP",
            "message": "恭喜你！你刚刚撞上了 1/2^128 的概率。请立刻去买彩票，别上传文件了。",
            "detail": "Hash Collision Detected. This should be impossible."
        }
    )
2. 前端：解锁成就 (Achievement Unlocked)
前端捕获到 418 状态码时，不要显示红色的错误框，而是弹出一个金色的传说级弹窗，甚至可以放点烟花特效。

前端代码思路 (ActionArea.vue)：

JavaScript
// 在处理上传响应时
if (response.status === 418) {
  const data = await response.json();
  
  // 触发彩蛋 UI
  showGoldenModal({
    title: "🏆 成就解锁：天选之子",
    body: "你上传的文件触发了 MD5 哈希碰撞！这种情况在人类文明史上可能只会出现一次。",
    footer: "错误详情：" + data.message
  });
  
  return; // 中断上传流程
}
3. 日志：留给未来的信
如果真的发生了，这可能意味着 MD5 算法被彻底破解，或者更科幻一点——发生了比特翻转 (Bit Flip)，比如高能宇宙射线击中了你的服务器内存。

你可以把日志写得更中二一点：

[CRITICAL] 检测到时空扰动。如果不是算法被破解，就是未来人类正在尝试通过哈希碰撞向我们发送信号。

==============================================================




为了实现秒传（去重存储）和多用户/多场景复用，我们需要将其拆分为：

物理存储表 (PhysicalFile)：只关心文件实体，以 Hash 为身份证。

业务逻辑表 (SensorFile)：关心这个文件“被谁传的”、“叫什么名”、“处理状态如何”。

以下是基于 SQLModel 的双表设计方案：

1. 概念设计图解
物理表 (PhysicalFile): 仓库管理员。只管存货，不管谁送来的。只要 Hash 一样，就是同一个货。

逻辑表 (SensorFile): 业务登记员。记录每次上传的单据，引用物理表的货物。

2. 代码实现 (SQLModel)
Python
from typing import Optional, List
from datetime import datetime
import uuid
from sqlmodel import SQLModel, Field, Relationship
from sqlalchemy import Column, JSON

# ==========================================
# 表 1: 物理文件表 (只存唯一的 Raw Data)
# ==========================================
class PhysicalFile(SQLModel, table=True):
    """
    物理存储表;
    核心职责：去重。只要 Hash 相同，硬盘上只存一份，数据库里只有这一行。
    """
    __tablename__ = "physical_files"

    # 核心字段
    hash: str = Field(primary_key=True, index=True, description="文件的 MD5/SHA256，绝对唯一的主键")
    size: int = Field(description="文件大小(Bytes)")
    path: str = Field(description="Zstd 压缩文件在磁盘/S3 上的物理路径")
    
    # 辅助字段
    created_at: datetime = Field(default_factory=datetime.now, description="物理文件首次入库时间")
    compression_ratio: Optional[str] = Field(default=None, description="压缩率统计")

    # 反向关系：一个物理文件可以对应多个业务记录
    sensor_files: List["SensorFile"] = Relationship(back_populates="physical_file")


# ==========================================
# 表 2: 业务逻辑表 (即你原来的 SensorFile)
# ==========================================
class SensorFile(SQLModel, table=True):
    """
    业务逻辑表;
    核心职责：记录用户的上传行为、文件名、元数据以及处理状态。
    """
    __tablename__ = "sensor_files"

    # 1. 身份标识 (使用 UUID，不再用 Hash)
    id: str = Field(default_factory=lambda: str(uuid.uuid4()), primary_key=True)
    
    # 2. 外键关联 (指向物理文件)
    file_hash: str = Field(foreign_key="physical_files.hash", index=True, description="关联到物理文件")
    
    # 3. 业务属性 (从用户原来的模型继承)
    filename: str = Field(description="用户上传时的原始文件名，允许重复")
    upload_time: str = Field(alias="uploadTime")
    
    # 传感器/设备元数据
    device_type: str = Field(alias="deviceType")
    device_model: str = Field(alias="deviceModel")
    
    # 测试相关
    test_type_l1: str = Field(default="Unknown", alias="testTypeL1")
    test_type_l2: str = Field(default="--", alias="testTypeL2")
    notes: str = Field(default="")
    
    # 处理流程状态 (这些属于业务逻辑，不同次上传可能状态不同，所以放这里)
    status: str = Field(default="Idle") 
    progress: Optional[int] = None
    error_message: Optional[str] = Field(default=None, alias="errorMessage")
    
    # 分析结果数据
    # 注意：如果分析结果也是一一对应 Hash 的，其实可以移到 PhysicalFile。
    # 但为了灵活（比如重跑分析），放在这里更合适。
    duration: str = Field(default="--")
    packets: str = Field(default="[]") # 建议后续改为 JSON 类型存储
    content_meta: Optional[dict] = Field(default={}, sa_column=Column(JSON))
    processed_dir: Optional[str] = Field(default=None, alias="processedDir")

    # 关系属性
    physical_file: Optional[PhysicalFile] = Relationship(back_populates="sensor_files")

    class Config:
        populate_by_name = True